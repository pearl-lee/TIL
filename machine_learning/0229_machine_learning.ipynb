{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 머신러닝(machine learning, 기계학습)의 개념\n",
    "- 인공지능의 한 분야로 컴퓨터가 학습할 수 있도록 하는 알고리즘과 기술을 개발하는 분야\n",
    "---\n",
    "### 지도학습(superviesd learning)\n",
    "- $Y = f(X)$ \n",
    "- 주어진 데이터를 통해서 입력변수(X)와 출력변수(Y)간의 관계를 나타내는 함수 f를 만드는 것\n",
    "- 입력변수(X)와 출력변수(Y)의 관계에 대해 모델링\n",
    "- X로 Y를 예측 또는 분류하는 문제\n",
    "    - 회귀(regression) : 연속형 출력변수 Y를 예측 \n",
    "        - (ex)주식가격 예측\n",
    "    - 분류(classification) : 이산형 출력변수 Y를 예측\n",
    "        - (ex)공정 불량 여부 탐지\n",
    "- input/output, Labeled Data\n",
    "\n",
    "####  $\\checkmark $ 선형회귀분석(Linear Regression)\n",
    "- 독립변수와 종속변수가 선형적인 관계를 가진다는 가정하에 분석\n",
    "- 직선을 통해 종속변수 예측. 독립변수의 중요도돠 영향력을 파악하기 쉬움\n",
    "\n",
    "#### $\\checkmark $  의사결정 나무(Decision Tree)\n",
    "- 독립변수 조건에 따라 조속변수를 분리\n",
    "- 과적합(overfitting)이 잘 일어남\n",
    "\n",
    "#### $\\checkmark $ 3. KNN(K-Nearest Neighbor)\n",
    "- 새로 들어온 데이터를 주변 k개의 데이터의 class로 분류하는 기법\n",
    "\n",
    "#### $\\checkmark $ 4. Neural Network (Deep Learning)\n",
    "- 입력(input), 은닉(hidden), 출력(output) 층으로 구성된 모형\n",
    "- 각 층을 연결하는 노드의 가중치를 업데이트 하며 학습\n",
    "- overfitting이 많이 발생\n",
    "\n",
    "#### $\\checkmark $ 5. SVM(Support Vector Machine)\n",
    "- class간의 거리(margin)가 최대가 되도록 decision boundary를 만드는 방법\n",
    "- 학습과정에서 어느정도 오차 허용\n",
    "- 학습시간이 오래걸려 최근에는 잘 쓰이지 않는 추세\n",
    "\n",
    "#### $\\checkmark $ 6. Ensemble Learning\n",
    "- 여러개의 모델을 결합하여 사용하는 모델\n",
    "\n",
    "---\n",
    "### 비지도학습(unsupervised learning)\n",
    "- 주어진 데이터 속에서 데이터의 특징을 찾아내는 함수 f를 만드는 것\n",
    "- 출력변수(Y)가 존재하지 않고, 입력변수(X) 간의 관계에 대해 모델링\n",
    "    - 군집분석 : 유사한 데이터끼리 그룹화\n",
    "        - (ex)고객 분류(segmentation)\n",
    "    - PCA : 독립변수들의 차원을 축소화\n",
    "- input, Unlabeled Data\n",
    "\n",
    "#### $\\checkmark $ K-means clustering\n",
    "- label없이 k개의 데이터의 군집 생성\n",
    "\n",
    "---\n",
    "### 강화학습(reinforcement learning)\n",
    "- 수 많은 시뮬레이션을 통해 현재의 선택이 먼 미래의 보상이 최대가 되도록 학습\n",
    "- Agnet가 action(학습대상)을 취하고 Environment에서 보상을 받고, 이 보상이 최대가 되도록 최적의 action을 취하는 방법을 학습\n",
    "    - (ex)AlphaGo\n",
    "- no dataset, state&action, simulation, decision making\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "#### 과적합(overfitting)\n",
    "- 모형이 복잡할수록, 데이터가 적을수록 과적합이 일어나기 쉬움\n",
    "- data science와 AI 분야에서 큰 이슈\n",
    "\n",
    "#### 분산과 편파성의 Trade-off (Dilemma)\n",
    "- 모형 $\\hat{f}(X)$으로 모집단 전체 데이터를 예측할 때 발생하는 총 error는 \n",
    "- reducible error와 irreducible error로 표현되며, reducible error는 다시 분산과 편파성으로 구성\n",
    "\n",
    "    $E(Y-\\hat{Y})^2 = E[f(X) + \\epsilon - \\hat{f}(X)]^2 = Var(\\hat{f}(X)) + [Bias(\\hat{f}(X))]^2 + Var(\\epsilon)$\n",
    "    \n",
    "    - $E(Y-\\hat{Y})^2$ : MSE(Mean Squared of Error)(기댓값)\n",
    "    - $Var(\\hat{f}(X))$ : 분산(Variance)\n",
    "    - $[Bias(\\hat{f}(X))]^2$ : 편파성(Bias)\n",
    "    - $Var(\\epsilon)$ : irreducible error\n",
    "    \n",
    "\n",
    "- 분산(Variance) : 전체 데이터 집합 중 다른 학습 데이터를 이용했을 때, $\\hat{f}$이 변하는 정도\n",
    "    - 모형이 복잡할 수록 분산이 높음\n",
    "- 편파성(Bias) : 학습 알고리즘에서 잘못된 가정을 했을 때 발생하는 오차\n",
    "    - 간단한 모형일 수록 편파성이 높음\n",
    "- 복잡한 모형 $\\hat{f}(X)$을 사용하여 편파성을 줄이면, 반대로 분산이 커짐\n",
    "    - 간단한 모형일 경우 반대의 현상 발생\n",
    "- 따라서 분산과 편파성이 작은 모형을 찾아야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 모형의 적합성 평가방법\n",
    "- MSE(Mean Squared of Error), 복잡도\n",
    "- 학습데이터의 MSE는 복잡한 모형일 수록 감소하지만, 검증데이터의 MSE는 일정 시점 이후로 증가\n",
    "- MSE가 증가하는 원인은 모형이 학습데이터에 과적합(overfitting)되기 때문.\n",
    "    - 낮은 복잡도를 가지면, 편파성이 높아져 가장 높은 MSE값을 가짐\n",
    "    - 너무 높은 복잡도를 가지면 학습데이터에 과적합되어 분산이 높아짐. 검증데이터의 MSE가 높아짐\n",
    "    - 모형과 유사한 형태로 예측을 하면, 분산과 편파성이 모두 적절히 낮아져  검증데이터의 MSE가 가장 낮아짐\n",
    "    \n",
    "#### 데이터 분할\n",
    "- 과적합을 방지하기 위해 전체 데이터를 학습(train), 검증(validation), 시험(test) 데이터로 나누며 비율을 보통 5:3:2로 정한다\n",
    "    - training data : 모형 f를 추정(학습)하는데 필요\n",
    "    - validation data : 추정한 모형 f가 적합한지 검증하고, hyper parameter를 조정함\n",
    "    - test data : 최종적으로 선택한 모형의 성능을 평가\n",
    "\n",
    "#### K-Fold Cross Validation(교차검증)\n",
    "- 모형의 적합성을 보다 객관적으로 평가하기 위한 방법\n",
    "- 데이터를 $k$(주로 5 또는 10)개 부분으로 나눈 뒤, 그 중 하나를 검증집합, 나머지를 학습집합으로 분류\n",
    "- 위 과정을 $k$번 반복하고 $k$개의 성능 지표를 평균하여 모형의 적합성 평가\n",
    "\n",
    "#### LOOCV(Leave-One-Out Cross Validation)\n",
    "- 데이터 수가 적을 때 사용하는 교차검증\n",
    "- 총 $n$(데이터 수 만큼)개의 모델을 만듦\n",
    "- 각 모델은 하나의 샘플만 제외하고 모델을 만들고, 제외한 샘플로 성능지표를 계산\n",
    "- 이렇게 도출된 $n$개의 성능지표를 평균내어 최종 성능지표 도출\n",
    "\n",
    "#### 데이터 분석과정\n",
    "`raw 데이터 -> 전처리된 데이터 -> 실험설계 -> Model 도출`\n",
    "\n",
    "- 전처리\n",
    "    - raw 데이터를 모델링 할 수 있도록 데이터를 병합하거나 파생변수 생성\n",
    "- 실험설계\n",
    "    - 실험설계에서 test data는 실제로 우리가 모델을 적용한다는 가정을 해야함\n",
    "    - train data, validation data에 test에 대한 정보는 없어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
